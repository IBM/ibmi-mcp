"""
Test script for IBM i Specialized Agents (LangGraph Implementation)

This script tests all four specialized agents with Ollama gpt-oss:20b model.

Usage:
    uv run test_specialized_agents.py
    uv run test_specialized_agents.py --agent performance
    uv run test_specialized_agents.py --interactive
"""

import asyncio
import sys
import os

# Disable LangSmith tracing for tests
os.environ["LANGCHAIN_TRACING_V2"] = "false"

from ibmi_agents import (
    create_ibmi_agent,
    list_available_agents,
    chat_with_agent,
    AVAILABLE_AGENTS,
    set_verbose_logging,
    get_verbose_logging,
)

# Test queries for each agent type
TEST_QUERIES = {
    "performance": "What is my system status? Give me CPU and memory metrics.",
    "discovery": "Give me an overview of available system services.",
    "browse": "Show me services in the QSYS2 schema.",
    "search": "Search for services related to system status."
}

async def test_single_agent(agent_type: str, model_id: str = "gpt-oss:20b"):
    """Test a single agent with a sample query."""
    print(f"\n{'='*80}")
    print(f"Testing {agent_type.upper()} Agent")
    print(f"{'='*80}\n")
    
    try:
        # Create agent context
        print(f"üîß Creating {agent_type} agent with model {model_id}...")
        ctx = await create_ibmi_agent(agent_type, model_id=model_id)
        
        async with ctx as (agent, session):
            print(f"‚úÖ Agent created: {agent.name}\n")
            
            # Get test query
            query = TEST_QUERIES.get(agent_type, "What can you help me with?")
            print(f"üìù Test Query: {query}\n")
            print(f"{'‚îÄ'*80}\n")
            
            # Send query and get response (session is active here)
            print("ü§ñ Agent processing...\n")
            response = await chat_with_agent(
                agent,
                query,
                thread_id=f"test-{agent_type}-1"
            )
            
            print(f"{'‚îÄ'*80}")
            print(f"‚úÖ Response:\n")
            print(response)
            print(f"\n{'‚îÄ'*80}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Error testing {agent_type} agent: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_all_agents(model_id: str = "gpt-oss:20b"):
    """Test all available agents."""
    print("\n" + "="*80)
    print("IBM i Specialized Agents - Full Test Suite")
    print("="*80)
    print(f"Model: {model_id}")
    print(f"Agents: {len(AVAILABLE_AGENTS)}")
    print("="*80)
    
    # List available agents
    agents_info = list_available_agents()
    print("\nAvailable Agents:")
    for agent_type, description in agents_info.items():
        print(f"  ‚Ä¢ {agent_type}: {description}")
    
    # Test each agent
    results = {}
    for agent_type in AVAILABLE_AGENTS.keys():
        success = await test_single_agent(agent_type, model_id)
        results[agent_type] = success
    
    # Summary
    print(f"\n{'='*80}")
    print("Test Summary")
    print(f"{'='*80}\n")
    
    for agent_type, success in results.items():
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"  {status} - {agent_type}")
    
    total_passed = sum(results.values())
    total_tests = len(results)
    print(f"\n{'‚îÄ'*80}")
    print(f"Total: {total_passed}/{total_tests} agents passed")
    print(f"{'='*80}\n")
    
    return all(results.values())

async def interactive_mode(agent_type: str, model_id: str = "gpt-oss:20b"):
    """Interactive chat mode with a specific agent."""
    print(f"\n{'='*80}")
    print(f"Interactive Mode - {agent_type.upper()} Agent")
    print(f"{'='*80}\n")
    
    try:
        # Create agent context
        print(f"üîß Initializing {agent_type} agent with {model_id}...\n")
        ctx = await create_ibmi_agent(agent_type, model_id=model_id)
        
        async with ctx as (agent, session):
            print(f"‚úÖ {agent.name} ready!\n")
            
            # Show agent info
            agents_info = list_available_agents()
            print(f"üìã Agent Purpose: {agents_info[agent_type]}\n")
            print(f"{'‚îÄ'*80}")
            print("üí¨ Interactive mode active. Type 'quit', 'exit', or 'q' to stop.\n")
            
            thread_id = f"interactive-{agent_type}"
            message_count = 0
            
            while True:
                try:
                    # Get user input
                    user_input = input("üë§ You: ").strip()
                    
                    # Check for exit commands
                    if user_input.lower() in ['quit', 'exit', 'q']:
                        print("\nüëã Goodbye!")
                        break
                    
                    # Skip empty input
                    if not user_input:
                        continue
                    
                    message_count += 1
                    print()
                    
                    # Get agent response (session is active)
                    response = await chat_with_agent(agent, user_input, thread_id)
                    
                    print(f"ü§ñ {agent.name}:\n")
                    print(response)
                    print(f"\n{'‚îÄ'*80}\n")
                    
                except KeyboardInterrupt:
                    print("\n\nüëã Interrupted. Goodbye!")
                    break
                except Exception as e:
                    print(f"\n‚ùå Error: {e}\n")
            
            print(f"\nüìä Session stats: {message_count} messages exchanged")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

async def quick_test(model_id: str = "gpt-oss:20b"):
    """Quick test - just verify all agents can be created."""
    print("\n" + "="*80)
    print("Quick Agent Creation Test")
    print("="*80)
    print(f"Model: {model_id}\n")
    
    results = {}
    
    for agent_type in AVAILABLE_AGENTS.keys():
        try:
            print(f"Creating {agent_type} agent...", end=" ")
            ctx = await create_ibmi_agent(agent_type, model_id=model_id)
            async with ctx as (agent, session):
                print(f"‚úÖ {agent.name}")
                results[agent_type] = True
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            results[agent_type] = False
    
    print(f"\n{'‚îÄ'*80}")
    total_passed = sum(results.values())
    total_tests = len(results)
    print(f"Result: {total_passed}/{total_tests} agents created successfully")
    print(f"{'='*80}\n")
    
    return all(results.values())

def main():
    """Main entry point with argument parsing."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Test IBM i Specialized Agents (LangGraph)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Test all agents with verbose output (default)
  uv run test_specialized_agents.py
  
  # Test specific agent
  uv run test_specialized_agents.py --agent performance
  
  # Test with quiet mode (only final responses)
  uv run test_specialized_agents.py --agent performance --quiet
  
  # Interactive mode with specific agent
  uv run test_specialized_agents.py --agent performance --interactive
  
  # Quick creation test
  uv run test_specialized_agents.py --quick
  
  # Use different model
  uv run test_specialized_agents.py --model gpt-4o
        """
    )
    
    parser.add_argument(
        "--agent",
        choices=list(AVAILABLE_AGENTS.keys()),
        help="Test specific agent type"
    )
    
    parser.add_argument(
        "--interactive",
        action="store_true",
        help="Run in interactive chat mode (requires --agent)"
    )
    
    parser.add_argument(
        "--model",
        default="gpt-oss:20b",
        help="Model to use (default: gpt-oss:20b)"
    )
    
    parser.add_argument(
        "--quick",
        action="store_true",
        help="Quick test - just verify agents can be created"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        default=True,
        help="Enable verbose logging with tool calls and responses (default: True)"
    )
    
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Disable verbose logging (only show final responses)"
    )
    
    args = parser.parse_args()
    
    # Set verbose logging based on flags
    if args.quiet:
        set_verbose_logging(False)
    elif args.verbose:
        set_verbose_logging(True)
    
    # Validate arguments
    if args.interactive and not args.agent:
        parser.error("--interactive requires --agent to be specified")
    
    # Run appropriate test mode
    try:
        if args.quick:
            success = asyncio.run(quick_test(args.model))
        elif args.interactive:
            asyncio.run(interactive_mode(args.agent, args.model))
            success = True
        elif args.agent:
            success = asyncio.run(test_single_agent(args.agent, args.model))
        else:
            success = asyncio.run(test_all_agents(args.model))
        
        # Exit with appropriate code
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Test interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
