---
title: "System Monitoring Tutorial"
description: "Step-by-step tutorial for building a comprehensive IBM i system monitoring solution using the performance toolset."
---

# System Monitoring Tutorial

This tutorial walks through building a comprehensive IBM i system monitoring solution using the actual tools from the performance.yaml configuration. You'll learn to monitor system health, analyze job performance, and track resource utilization.

<Info>
This tutorial uses real IBM i system queries from the prebuilt performance configuration. All examples are production-ready and can be adapted for your monitoring needs.
</Info>

## Prerequisites

Before starting, ensure you have:

<CardGroup cols={2}>
  <Card title="MCP Server Running" icon="server">
    **IBM i MCP Server Active**
    
    - MCP server running on port 3010
    - Performance toolset loaded
    - Valid IBM i connection configured
    - MCP Inspector available for testing
  </Card>
  
  <Card title="System Access" icon="key">
    **IBM i Database Access**
    
    - User with SELECT permissions on QSYS2 views
    - Access to ACTIVE_JOB_INFO() function
    - Permission to query system status tables
    - Network connectivity to IBM i system
  </Card>
</CardGroup>

## Step 1: Basic System Health Check

Let's start with the fundamental system monitoring tools from the performance configuration.

### 1. Get Overall System Status

Using the `system_status` tool from performance.yaml:

<CodeGroup>
```bash MCP Inspector
# Launch MCP Inspector
npx @modelcontextprotocol/inspector http://localhost:3010

# Execute system_status tool
Tool: system_status
Arguments: {}
```

```bash curl Command
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "system_status",
    "arguments": {}
  }'
```

```json Expected Response
{
  "structuredContent": {
    "data": [
      {
        "SYSTEM_NAME": "MYIBMI",
        "MAIN_STORAGE_SIZE": 8388608,
        "CURRENT_UNPROTECTED_USED": 2145386,
        "CPU_UTILIZATION": 15.2,
        "JOBS_IN_SYSTEM": 1247,
        "BATCH_JOBS_RUNNING": 45,
        "INTERACTIVE_JOBS": 12,
        "ELAPSED_TIME": "0000014523456789"
      }
    ],
    "rowCount": 1
  }
}
```
</CodeGroup>

**Understanding the Results:**
- `CPU_UTILIZATION`: Current CPU usage percentage
- `MAIN_STORAGE_SIZE`: Total system memory in KB
- `CURRENT_UNPROTECTED_USED`: Memory currently in use
- `JOBS_IN_SYSTEM`: Total number of active jobs
- `BATCH_JOBS_RUNNING`: Number of batch jobs processing

### 2. Analyze System Activity

Use the `system_activity` tool for detailed activity metrics:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "system_activity",
    "arguments": {}
  }'
```

This provides real-time activity data including:
- Transaction rates
- Disk I/O statistics  
- Communication activity
- Database operations

### 3. Check Memory Pool Status

Monitor memory allocation with the `memory_pools` tool:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "memory_pools",
    "arguments": {}
  }'
```

**Key Metrics to Watch:**
- Pool utilization percentages
- Thread counts vs maximums
- Reserved vs available memory

## Step 2: Job Performance Analysis

Now let's dive deep into job performance using the performance toolset.

### 1. Identify Top CPU Consumers

Use the `active_job_info` tool to find resource-intensive jobs:

<CodeGroup>
```bash Default Query (Top 10)
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "active_job_info",
    "arguments": {
      "limit": 10
    }
  }'
```

```bash Extended Analysis (Top 25)
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "active_job_info", 
    "arguments": {
      "limit": 25
    }
  }'
```

```json Sample Response
{
  "structuredContent": {
    "data": [
      {
        "CPU_TIME": 1234567,
        "JOB_NAME": "QZSOASYN",
        "JOB_USER": "QTMHHTTP",
        "JOB_NUMBER": "123456",
        "JOB_TYPE": "BCH",
        "JOB_STATUS": "ACTIVE", 
        "SUBSYSTEM_NAME": "QUSRWRK",
        "TOTAL_DISK_IO_COUNT": 45678,
        "TEMPORARY_STORAGE": 1024000,
        "RUN_PRIORITY": 20
      }
    ]
  }
}
```
</CodeGroup>

**Analysis Points:**
- **CPU_TIME**: Total CPU consumption (higher = more resource intensive)
- **JOB_TYPE**: BCH (batch), INT (interactive), SBS (subsystem)  
- **SUBSYSTEM_NAME**: QUSRWRK, QSYSWRK, QSERVER, etc.
- **TOTAL_DISK_IO_COUNT**: Disk activity indicator
- **RUN_PRIORITY**: Lower numbers = higher priority

### 2. Monitor HTTP Server Performance

Check web server metrics with the `http_server` tool:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "http_server",
    "arguments": {}
  }'
```

**Key HTTP Metrics:**
- Active vs idle threads
- Total requests and rejections
- SSL vs normal connections
- Response times and throughput

### 3. Check Remote Connections

Monitor system connectivity with the `remote_connections` tool:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "remote_connections",
    "arguments": {}
  }'
```

This counts established remote connections, helping identify:
- External system load
- Client connection patterns
- Potential security concerns

## Step 3: Storage and Resource Monitoring  

### 1. Analyze Temporary Storage

Monitor temporary storage usage patterns:

<CodeGroup>
```bash Named Storage Buckets
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "temp_storage_buckets", 
    "arguments": {}
  }'
```

```bash Unnamed Storage Summary
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "unnamed_temp_storage",
    "arguments": {}
  }'
```
</CodeGroup>

**Storage Analysis:**
- **CURRENT_SIZE**: Active temporary storage usage
- **PEAK_SIZE**: Maximum usage reached
- **Growth Patterns**: Compare current vs peak for trends

### 2. Review System Values

Check critical system values affecting performance:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "system_values",
    "arguments": {}
  }'
```

**Important System Values:**
- QMAXJOB: Maximum jobs allowed
- QACTJOB: Maximum active jobs
- QMAXSIGN: Maximum sign-on attempts
- QCACHE: Database cache settings

## Step 4: Collection Services Analysis

### 1. Check Collection Services Status

Monitor performance data collection:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "collection_services",
    "arguments": {}
  }'
```

### 2. Review Collection Categories

Analyze specific performance categories:

```bash
curl -X POST http://localhost:3010/mcp/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "name": "collection_categories",
    "arguments": {}
  }'
```

**Collection Categories:**
- *DISC: Disk utilization
- *COMM: Communication performance  
- *SYSTEM: Overall system metrics
- *JOB: Job-level performance data

## Step 5: Building a Monitoring Dashboard

### 1. Create a Monitoring Script

Combine multiple tools for comprehensive monitoring:

```python
# monitor_ibmi.py
import requests
import json
import time
from datetime import datetime

class IBMiMonitor:
    def __init__(self, mcp_url="http://localhost:3010/mcp/tools/call"):
        self.mcp_url = mcp_url
        
    def call_tool(self, tool_name, arguments={}):
        """Call an MCP tool and return the response."""
        payload = {
            "name": tool_name,
            "arguments": arguments
        }
        
        response = requests.post(
            self.mcp_url,
            headers={"Content-Type": "application/json"},
            data=json.dumps(payload)
        )
        
        return response.json()
    
    def get_system_health(self):
        """Get overall system health metrics."""
        print(f"=== System Health Check - {datetime.now()} ===")
        
        # System status
        status = self.call_tool("system_status")
        if status.get("structuredContent", {}).get("data"):
            data = status["structuredContent"]["data"][0]
            print(f"System: {data.get('SYSTEM_NAME')}")
            print(f"CPU Utilization: {data.get('CPU_UTILIZATION')}%")
            print(f"Memory Usage: {data.get('CURRENT_UNPROTECTED_USED'):,} KB of {data.get('MAIN_STORAGE_SIZE'):,} KB")
            print(f"Total Jobs: {data.get('JOBS_IN_SYSTEM')}")
            print(f"Batch Jobs: {data.get('BATCH_JOBS_RUNNING')}")
        
        # Memory pools
        pools = self.call_tool("memory_pools")
        if pools.get("structuredContent", {}).get("data"):
            print("\n--- Memory Pools ---")
            for pool in pools["structuredContent"]["data"][:5]:  # Top 5 pools
                utilization = (pool.get("CURRENT_THREADS", 0) / 
                             max(pool.get("MAXIMUM_ACTIVE_THREADS", 1), 1)) * 100
                print(f"{pool.get('POOL_NAME')}: {utilization:.1f}% utilized "
                      f"({pool.get('CURRENT_THREADS')}/{pool.get('MAXIMUM_ACTIVE_THREADS')} threads)")
        
        # Top CPU consumers
        jobs = self.call_tool("active_job_info", {"limit": 5})
        if jobs.get("structuredContent", {}).get("data"):
            print("\n--- Top CPU Consumers ---")
            for job in jobs["structuredContent"]["data"]:
                print(f"{job.get('JOB_NAME')} ({job.get('JOB_USER')}): "
                      f"CPU={job.get('CPU_TIME'):,}, I/O={job.get('TOTAL_DISK_IO_COUNT'):,}")
        
        print("\n" + "="*60 + "\n")
    
    def monitor_continuously(self, interval=60):
        """Monitor system continuously with specified interval."""
        print("Starting IBM i System Monitoring...")
        print(f"Checking system health every {interval} seconds")
        print("Press Ctrl+C to stop")
        
        try:
            while True:
                self.get_system_health()
                time.sleep(interval)
        except KeyboardInterrupt:
            print("Monitoring stopped.")

# Usage
if __name__ == "__main__":
    monitor = IBMiMonitor()
    
    # Single health check
    monitor.get_system_health()
    
    # Continuous monitoring (uncomment to enable)
    # monitor.monitor_continuously(interval=300)  # Every 5 minutes
```

### 2. Run the Monitor

```bash
# Install dependencies
pip install requests

# Set environment variables for MCP server
export DB2i_HOST="your-ibmi-system"
export DB2i_USER="your-username"
export DB2i_PASS="your-password"

# Start MCP server (if not running)
npm run start:http

# Run the monitor
python monitor_ibmi.py
```

### 3. Expected Output

```
=== System Health Check - 2024-03-20 10:30:00 ===
System: MYIBMI
CPU Utilization: 15.2%
Memory Usage: 2,145,386 KB of 8,388,608 KB
Total Jobs: 1247
Batch Jobs: 45

--- Memory Pools ---
*MACHINE: 85.2% utilized (42/50 threads)
*BASE: 45.8% utilized (275/600 threads)
*INTERACT: 12.0% utilized (12/100 threads)
*SPOOL: 8.3% utilized (5/60 threads)
*SHRPOOL1: 90.0% utilized (18/20 threads)

--- Top CPU Consumers ---
QZSOASYN (QTMHHTTP): CPU=1,234,567, I/O=45,678
QZSOASAP (QTMHHTTP): CPU=987,654, I/O=32,109
QTRDTSRV (*NONE): CPU=654,321, I/O=21,456
QSYSARB (*NONE): CPU=456,789, I/O=15,678
QP0ZSPWP (QTMHHTTP): CPU=321,987, I/O=12,345
============================================================
```

## Step 6: Setting Up Alerts

### 1. Alert Configuration

Create alert thresholds based on your monitoring:

```python
# alerts.py
class IBMiAlerts:
    def __init__(self):
        self.thresholds = {
            "cpu_utilization": 80.0,      # CPU percentage
            "memory_utilization": 85.0,   # Memory percentage
            "job_count": 2000,            # Total job count
            "pool_utilization": 90.0      # Memory pool percentage
        }
        
    def check_alerts(self, monitor):
        """Check system metrics against alert thresholds."""
        alerts = []
        
        # Get system status
        status = monitor.call_tool("system_status")
        if status.get("structuredContent", {}).get("data"):
            data = status["structuredContent"]["data"][0]
            
            # CPU alert
            cpu = data.get("CPU_UTILIZATION", 0)
            if cpu > self.thresholds["cpu_utilization"]:
                alerts.append(f"HIGH CPU: {cpu}% (threshold: {self.thresholds['cpu_utilization']}%)")
            
            # Memory alert
            used = data.get("CURRENT_UNPROTECTED_USED", 0)
            total = data.get("MAIN_STORAGE_SIZE", 1)
            memory_pct = (used / total) * 100
            if memory_pct > self.thresholds["memory_utilization"]:
                alerts.append(f"HIGH MEMORY: {memory_pct:.1f}% (threshold: {self.thresholds['memory_utilization']}%)")
            
            # Job count alert
            jobs = data.get("JOBS_IN_SYSTEM", 0)
            if jobs > self.thresholds["job_count"]:
                alerts.append(f"HIGH JOB COUNT: {jobs} (threshold: {self.thresholds['job_count']})")
        
        # Memory pool alerts
        pools = monitor.call_tool("memory_pools")
        if pools.get("structuredContent", {}).get("data"):
            for pool in pools["structuredContent"]["data"]:
                current = pool.get("CURRENT_THREADS", 0)
                maximum = pool.get("MAXIMUM_ACTIVE_THREADS", 1)
                utilization = (current / maximum) * 100
                
                if utilization > self.thresholds["pool_utilization"]:
                    alerts.append(f"HIGH POOL UTILIZATION: {pool.get('POOL_NAME')} "
                                f"{utilization:.1f}% (threshold: {self.thresholds['pool_utilization']}%)")
        
        return alerts
    
    def send_alerts(self, alerts):
        """Send alerts (implement your preferred notification method)."""
        if alerts:
            print("ðŸš¨ SYSTEM ALERTS ðŸš¨")
            for alert in alerts:
                print(f"  - {alert}")
            
            # Add your notification logic here:
            # - Send email
            # - Post to Slack
            # - Write to log file
            # - Trigger SNMP trap
            
        else:
            print("âœ… All systems normal")

# Integration with monitor
monitor = IBMiMonitor()
alerts = IBMiAlerts()

# Check for alerts
alert_list = alerts.check_alerts(monitor)
alerts.send_alerts(alert_list)
```

### 2. Automated Monitoring Service

Create a systemd service for continuous monitoring:

```ini
# /etc/systemd/system/ibmi-monitor.service
[Unit]
Description=IBM i System Monitor
After=network.target

[Service]
Type=simple
User=monitor
WorkingDirectory=/opt/ibmi-monitor
ExecStart=/usr/bin/python3 /opt/ibmi-monitor/monitor_ibmi.py
Restart=always
RestartSec=30
Environment=DB2i_HOST=your-ibmi-system
Environment=DB2i_USER=monitor_user
Environment=DB2i_PASS=monitor_password

[Install]
WantedBy=multi-user.target
```

```bash
# Enable and start the service
sudo systemctl enable ibmi-monitor
sudo systemctl start ibmi-monitor

# Check status
sudo systemctl status ibmi-monitor
```

## Step 7: Advanced Monitoring Patterns

### 1. Historical Trend Analysis

Track performance trends over time:

```python
# trends.py
import sqlite3
from datetime import datetime, timedelta

class TrendAnalyzer:
    def __init__(self, db_path="ibmi_metrics.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize SQLite database for metrics storage."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                timestamp TEXT PRIMARY KEY,
                cpu_utilization REAL,
                memory_used INTEGER,
                memory_total INTEGER,
                job_count INTEGER,
                batch_jobs INTEGER
            )
        """)
        conn.commit()
        conn.close()
    
    def store_metrics(self, monitor):
        """Store current metrics in database."""
        status = monitor.call_tool("system_status")
        if status.get("structuredContent", {}).get("data"):
            data = status["structuredContent"]["data"][0]
            
            conn = sqlite3.connect(self.db_path)
            conn.execute("""
                INSERT OR REPLACE INTO metrics 
                (timestamp, cpu_utilization, memory_used, memory_total, job_count, batch_jobs)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                datetime.now().isoformat(),
                data.get("CPU_UTILIZATION"),
                data.get("CURRENT_UNPROTECTED_USED"),
                data.get("MAIN_STORAGE_SIZE"),
                data.get("JOBS_IN_SYSTEM"),
                data.get("BATCH_JOBS_RUNNING")
            ))
            conn.commit()
            conn.close()
    
    def analyze_trends(self, hours=24):
        """Analyze trends over specified time period."""
        conn = sqlite3.connect(self.db_path)
        since = (datetime.now() - timedelta(hours=hours)).isoformat()
        
        cursor = conn.execute("""
            SELECT timestamp, cpu_utilization, 
                   (memory_used * 100.0 / memory_total) as memory_pct,
                   job_count, batch_jobs
            FROM metrics 
            WHERE timestamp > ?
            ORDER BY timestamp
        """, (since,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if len(rows) < 2:
            print("Insufficient data for trend analysis")
            return
        
        # Calculate averages and trends
        cpu_values = [r[1] for r in rows if r[1] is not None]
        memory_values = [r[2] for r in rows if r[2] is not None]
        job_values = [r[3] for r in rows if r[3] is not None]
        
        print(f"=== Trend Analysis (Last {hours} hours) ===")
        print(f"CPU Utilization: Avg={sum(cpu_values)/len(cpu_values):.1f}%, "
              f"Min={min(cpu_values):.1f}%, Max={max(cpu_values):.1f}%")
        print(f"Memory Usage: Avg={sum(memory_values)/len(memory_values):.1f}%, "
              f"Min={min(memory_values):.1f}%, Max={max(memory_values):.1f}%")
        print(f"Job Count: Avg={sum(job_values)/len(job_values):.0f}, "
              f"Min={min(job_values)}, Max={max(job_values)}")
```

### 2. Performance Baselines

Establish performance baselines for comparison:

```python
# baselines.py
class PerformanceBaselines:
    def __init__(self, monitor):
        self.monitor = monitor
        self.baselines = self.calculate_baselines()
    
    def calculate_baselines(self, samples=10, interval=30):
        """Calculate performance baselines from multiple samples."""
        print(f"Calculating baselines from {samples} samples...")
        
        cpu_values = []
        memory_values = []
        job_values = []
        
        for i in range(samples):
            status = self.monitor.call_tool("system_status")
            if status.get("structuredContent", {}).get("data"):
                data = status["structuredContent"]["data"][0]
                cpu_values.append(data.get("CPU_UTILIZATION", 0))
                
                used = data.get("CURRENT_UNPROTECTED_USED", 0)
                total = data.get("MAIN_STORAGE_SIZE", 1)
                memory_values.append((used / total) * 100)
                
                job_values.append(data.get("JOBS_IN_SYSTEM", 0))
            
            if i < samples - 1:
                time.sleep(interval)
        
        return {
            "cpu_baseline": sum(cpu_values) / len(cpu_values),
            "memory_baseline": sum(memory_values) / len(memory_values),
            "job_baseline": sum(job_values) / len(job_values)
        }
    
    def compare_to_baseline(self):
        """Compare current metrics to established baselines."""
        status = self.monitor.call_tool("system_status")
        if status.get("structuredContent", {}).get("data"):
            data = status["structuredContent"]["data"][0]
            
            current_cpu = data.get("CPU_UTILIZATION", 0)
            current_memory = (data.get("CURRENT_UNPROTECTED_USED", 0) / 
                            data.get("MAIN_STORAGE_SIZE", 1)) * 100
            current_jobs = data.get("JOBS_IN_SYSTEM", 0)
            
            print("=== Baseline Comparison ===")
            print(f"CPU: {current_cpu:.1f}% (baseline: {self.baselines['cpu_baseline']:.1f}%) "
                  f"[{current_cpu - self.baselines['cpu_baseline']:+.1f}%]")
            print(f"Memory: {current_memory:.1f}% (baseline: {self.baselines['memory_baseline']:.1f}%) "
                  f"[{current_memory - self.baselines['memory_baseline']:+.1f}%]")
            print(f"Jobs: {current_jobs} (baseline: {self.baselines['job_baseline']:.0f}) "
                  f"[{current_jobs - self.baselines['job_baseline']:+.0f}]")
```

---

<Info>
This comprehensive monitoring tutorial demonstrates how to leverage the real IBM i system tools for production monitoring. Adapt these patterns to your specific environment and monitoring requirements.
</Info>